{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CJE Planning: Optimize Your Evaluation Budget\n",
    "\n",
    "Before running a large evaluation, answer these questions:\n",
    "\n",
    "- **How many samples** do I need?\n",
    "- **How many oracle labels** are worth the cost?\n",
    "- **What effect size** can I reliably detect?\n",
    "\n",
    "CJE's planning tools help you find the optimal allocation between cheap surrogate scores and expensive oracle labels.\n",
    "\n",
    "**This notebook requires no data to get started.** You can plan your evaluation with just an estimate of your judge's quality.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cimo-labs/cje/blob/main/examples/cje_planning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CJE\n",
    "!pip install -q --upgrade cje-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Planning (No Data Required)\n",
    "\n",
    "To plan your evaluation, you only need:\n",
    "\n",
    "1. **Judge quality estimate** — How well does your cheap judge predict oracle labels?\n",
    "2. **Cost model** — What does each judge/oracle call cost?\n",
    "\n",
    "### Estimating Judge Quality\n",
    "\n",
    "Judge quality is measured as **R²** — the fraction of oracle variance explained by your judge.\n",
    "\n",
    "| R² | Quality | Example |\n",
    "|----|---------|----------|\n",
    "| 0.9+ | Excellent | GPT-4 predicting human preference on clear tasks |\n",
    "| 0.7-0.9 | Good | Strong LLM judge on well-defined criteria |\n",
    "| 0.5-0.7 | Moderate | LLM judge on subjective tasks |\n",
    "| <0.5 | Weak | Misaligned judge or very noisy oracle |\n",
    "\n",
    "**Don't know R²?** If you know the correlation between judge and oracle, convert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import correlation_to_r2\n",
    "\n",
    "# If judge-oracle correlation is 0.8\n",
    "r2 = correlation_to_r2(0.8)\n",
    "print(f\"Correlation 0.8 → R² = {r2:.2f}\")\n",
    "\n",
    "# For monotone (nonlinear) relationships, R² is higher\n",
    "r2_monotone = correlation_to_r2(0.8, \"monotone\")\n",
    "print(f\"Correlation 0.8 (monotone) → R² = {r2_monotone:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Your Costs\n",
    "\n",
    "Use actual dollar costs per API call:\n",
    "\n",
    "| Surrogate (Judge) | Oracle | Cost Ratio |\n",
    "|-------------------|--------|------------|\n",
    "| GPT-4o-mini ($0.01) | GPT-4o ($0.16) | 16× |\n",
    "| Claude Haiku ($0.008) | Claude Sonnet ($0.09) | 11× |\n",
    "| Llama-70B ($0.002) | Human ($2.00) | 1000× |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import CostModel\n",
    "\n",
    "# Example: GPT-4o-mini as judge, GPT-4o as oracle\n",
    "cost = CostModel(\n",
    "    surrogate_cost=0.01,  # $/call for judge\n",
    "    oracle_cost=0.16      # $/call for oracle\n",
    ")\n",
    "\n",
    "print(f\"Surrogate: ${cost.surrogate_cost}/call\")\n",
    "print(f\"Oracle: ${cost.oracle_cost}/call\")\n",
    "print(f\"Cost ratio: {cost.oracle_cost/cost.surrogate_cost:.0f}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Simulation\n",
    "\n",
    "Now we can plan the evaluation. This simulates the variance structure for your judge quality and finds the optimal allocation.\n",
    "\n",
    "**Note:** The simulation takes ~30-60 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import simulate_planning\n",
    "\n",
    "# Plan with R²=0.7 (good judge) and $5,000 budget\n",
    "result = simulate_planning(\n",
    "    r2=0.7,\n",
    "    budget=5000,\n",
    "    cost_model=cost,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational explanation of results\n",
    "print(result.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed plan\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Tradeoffs\n",
    "\n",
    "### How Judge Quality Affects Planning\n",
    "\n",
    "Better judges (higher R²) mean:\n",
    "- Less calibration uncertainty → fewer oracle labels needed\n",
    "- Lower MDE for the same budget\n",
    "\n",
    "Let's see how different judge qualities affect the recommendation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import simulate_variance_model, plan_evaluation\n",
    "\n",
    "print(\"Judge Quality vs Planning (at $5,000 budget)\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'R²':<6} {'Quality':<12} {'MDE':<8} {'Oracle %':<10} {'Samples'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for r2, quality in [(0.5, \"Moderate\"), (0.7, \"Good\"), (0.9, \"Excellent\")]:\n",
    "    model = simulate_variance_model(r2=r2, verbose=False)\n",
    "    plan = plan_evaluation(budget=5000, variance_model=model, cost_model=cost)\n",
    "    print(f\"{r2:<6} {quality:<12} {plan.mde:<8.1%} {plan.oracle_fraction:<10.0%} {plan.n_samples:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Decomposition\n",
    "\n",
    "CJE's variance has two components:\n",
    "\n",
    "$$\\text{Var}(\\hat{\\theta}) = \\frac{\\sigma^2_{\\text{eval}}}{n} + \\frac{\\sigma^2_{\\text{cal}}}{m}$$\n",
    "\n",
    "- **σ²_eval** — Evaluation variance (noise in policy performance)\n",
    "- **σ²_cal** — Calibration variance (uncertainty in judge→oracle mapping)\n",
    "\n",
    "Better judges have lower σ²_cal, which shifts the optimal allocation toward more samples and fewer oracle labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show variance decomposition from our simulation\n",
    "print(f\"Variance decomposition (R² = {result.r2})\")\n",
    "print(f\"  Evaluation variance:  {result.eval_variance_fraction:.0%}\")\n",
    "print(f\"  Calibration variance: {result.cal_variance_fraction:.0%}\")\n",
    "\n",
    "if result.cal_variance_fraction > 0.5:\n",
    "    print(\"\\n→ Calibration dominates: investing in oracle labels has high impact\")\n",
    "else:\n",
    "    print(\"\\n→ Evaluation dominates: more samples matter more than more labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Budget vs MDE Planning\n",
    "\n",
    "Two ways to plan:\n",
    "\n",
    "1. **Budget-constrained**: \"I have $X — what MDE can I achieve?\"\n",
    "2. **MDE-constrained**: \"I need to detect X% — what will it cost?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import plan_for_mde\n",
    "\n",
    "# Use the variance model from our simulation\n",
    "model = result.variance_model\n",
    "\n",
    "# Budget-constrained: What can I detect with $10K?\n",
    "plan_10k = plan_evaluation(budget=10000, variance_model=model, cost_model=cost)\n",
    "print(f\"With $10,000 budget: MDE = {plan_10k.mde:.1%}\")\n",
    "\n",
    "# MDE-constrained: What does it cost to detect 2%?\n",
    "plan_2pct = plan_for_mde(target_mde=0.02, variance_model=model, cost_model=cost)\n",
    "print(f\"To detect 2% differences: ${plan_2pct.total_cost:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different MDE targets\n",
    "print(\"MDE vs Budget Tradeoff\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"{'MDE':<10} {'Budget':<15} {'Samples':<10} {'Oracle'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for target in [0.05, 0.03, 0.02, 0.015, 0.01]:\n",
    "    p = plan_for_mde(target_mde=target, variance_model=model, cost_model=cost)\n",
    "    print(f\"{target:.1%}       ${p.total_cost:>10,.0f}    {p.n_samples:>7,}   {p.m_oracle:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Planning Loop\n",
    "\n",
    "Planning is iterative. Start with one constraint and check if the other is acceptable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example planning session:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Start with budget constraint\n",
    "initial = plan_evaluation(budget=10000, variance_model=model, cost_model=cost)\n",
    "print(f\"\\n1. With $10K budget: MDE = {initial.mde:.1%}\")\n",
    "print(\"   → Too high, I need to detect 1.5% differences\")\n",
    "\n",
    "# Check what it costs to hit a tighter MDE\n",
    "target = plan_for_mde(target_mde=0.015, variance_model=model, cost_model=cost)\n",
    "print(f\"\\n2. To hit 1.5% MDE: need ${target.total_cost:,.0f}\")\n",
    "print(\"   → Too expensive\")\n",
    "\n",
    "# Find a compromise\n",
    "compromise = plan_for_mde(target_mde=0.02, variance_model=model, cost_model=cost)\n",
    "print(f\"\\n3. Compromise at 2% MDE: ${compromise.total_cost:,.0f}\")\n",
    "print(\"   → Acceptable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Tradeoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje.visualization import plot_planning_dashboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plot_planning_dashboard(model, cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Refining with Pilot Data (Optional)\n",
    "\n",
    "Simulation-based planning is great for feasibility checks and initial budgeting. For production planning, you can refine your estimates with real pilot data.\n",
    "\n",
    "### When to Collect a Pilot\n",
    "\n",
    "Collect pilot data when:\n",
    "- Simulation suggests the evaluation is **feasible** (budget/MDE look acceptable)\n",
    "- You want **more precise** variance estimates\n",
    "- You're **uncertain** about your judge quality estimate\n",
    "\n",
    "### Pilot Requirements\n",
    "\n",
    "| Size | Prompts | Oracle Labels | Oracle % |\n",
    "|------|---------|---------------|----------|\n",
    "| Minimum | 200 | 80 | 40% |\n",
    "| Recommended | 400 | 120-160 | 30-40% |\n",
    "\n",
    "**Key:** Oracle labels must be a random subset — don't cherry-pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Arena sample data as reference\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"arena_sample\")\n",
    "if not (DATA_DIR / \"fresh_draws\" / \"base_responses.jsonl\").exists():\n",
    "    print(\"Downloading sample data...\")\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "    (DATA_DIR / \"fresh_draws\").mkdir(exist_ok=True)\n",
    "    \n",
    "    BASE_URL = \"https://raw.githubusercontent.com/cimo-labs/cje/main/examples/arena_sample\"\n",
    "    for f in [\"base_responses.jsonl\", \"clone_responses.jsonl\", \n",
    "              \"parallel_universe_prompt_responses.jsonl\", \"unhelpful_responses.jsonl\"]:\n",
    "        urllib.request.urlretrieve(f\"{BASE_URL}/fresh_draws/{f}\", DATA_DIR / \"fresh_draws\" / f)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(f\"Data exists at {DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import fit_variance_model\n",
    "from cje.data.fresh_draws import load_fresh_draws_auto\n",
    "\n",
    "# Load pilot data\n",
    "pilot_data = load_fresh_draws_auto(\"arena_sample/fresh_draws\", \"base\")\n",
    "\n",
    "print(f\"Loaded: {len(pilot_data.samples)} samples\")\n",
    "print(f\"Oracle labels: {sum(1 for s in pilot_data.samples if s.oracle_label is not None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit variance model from pilot data (~30 seconds)\n",
    "pilot_model = fit_variance_model(pilot_data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare simulation vs pilot estimates\n",
    "sim_plan = plan_evaluation(budget=5000, variance_model=result.variance_model, cost_model=cost)\n",
    "pilot_plan = plan_evaluation(budget=5000, variance_model=pilot_model, cost_model=cost)\n",
    "\n",
    "print(\"Comparison: Simulation vs Pilot\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"{'Metric':<20} {'Simulation':<12} {'Pilot'}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'σ²_eval':<20} {result.variance_model.sigma2_eval:<12.4f} {pilot_model.sigma2_eval:.4f}\")\n",
    "print(f\"{'σ²_cal':<20} {result.variance_model.sigma2_cal:<12.4f} {pilot_model.sigma2_cal:.4f}\")\n",
    "print(f\"{'MDE':<20} {sim_plan.mde:<12.1%} {pilot_plan.mde:.1%}\")\n",
    "print(f\"{'Oracle fraction':<20} {sim_plan.oracle_fraction:<12.0%} {pilot_plan.oracle_fraction:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "**Simulation-based planning (no data required):**\n",
    "```python\n",
    "from cje import simulate_planning, CostModel, correlation_to_r2\n",
    "\n",
    "# Estimate judge quality\n",
    "r2 = correlation_to_r2(0.8)  # or use R² directly\n",
    "\n",
    "# Specify costs\n",
    "cost = CostModel(surrogate_cost=0.01, oracle_cost=0.16)\n",
    "\n",
    "# Plan\n",
    "result = simulate_planning(r2=r2, budget=5000, cost_model=cost)\n",
    "print(result.explain())\n",
    "```\n",
    "\n",
    "**Pilot-based planning (with data):**\n",
    "```python\n",
    "from cje import fit_variance_model, plan_evaluation, CostModel\n",
    "from cje.data.fresh_draws import load_fresh_draws_auto\n",
    "\n",
    "# Load and fit\n",
    "pilot = load_fresh_draws_auto(\"pilot_dir\", \"base\")\n",
    "model = fit_variance_model(pilot)\n",
    "\n",
    "# Plan\n",
    "cost = CostModel(surrogate_cost=0.01, oracle_cost=0.16)\n",
    "plan = plan_evaluation(budget=5000, variance_model=model, cost_model=cost)\n",
    "```\n",
    "\n",
    "### Decision Flowchart\n",
    "\n",
    "```\n",
    "Start\n",
    "  │\n",
    "  ▼\n",
    "Have pilot data? ──No──→ simulate_planning(r2, budget, cost)\n",
    "  │                              │\n",
    "  Yes                            ▼\n",
    "  │                      Is evaluation feasible?\n",
    "  ▼                              │\n",
    "fit_variance_model()      No ────┴──── Yes\n",
    "  │                       │            │\n",
    "  ▼                       ▼            ▼\n",
    "plan_evaluation()    Reconsider    Collect pilot\n",
    "                     (improve        (optional)\n",
    "                      judge or \n",
    "                      increase \n",
    "                      budget)\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Once you have your plan, run the evaluation:\n",
    "\n",
    "[![Core Tutorial](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cimo-labs/cje/blob/main/examples/cje_core_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: The Math\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "### Variance Decomposition\n",
    "\n",
    "CJE's variance decomposes into two independent components:\n",
    "\n",
    "$$\\text{Var}(\\hat{\\theta}) = \\frac{\\sigma^2_{\\text{eval}}}{n} + \\frac{\\sigma^2_{\\text{cal}}}{m}$$\n",
    "\n",
    "Where:\n",
    "- **n** = total samples (evaluated by cheap judge)\n",
    "- **m** = oracle-labeled samples (subset of n)\n",
    "- **σ²_eval** = evaluation variance (inherent noise in policy performance)\n",
    "- **σ²_cal** = calibration variance (uncertainty in learning judge→oracle mapping)\n",
    "\n",
    "### Square Root Allocation Law\n",
    "\n",
    "Given costs c_S (surrogate) and c_Y (oracle), the optimal allocation follows:\n",
    "\n",
    "$$\\frac{m^*}{n^*} = \\sqrt{\\frac{c_S}{c_Y}} \\cdot \\sqrt{\\frac{\\sigma^2_{\\text{cal}}}{\\sigma^2_{\\text{eval}}}}$$\n",
    "\n",
    "This balances the marginal variance reduction per dollar spent on each component.\n",
    "\n",
    "### MDE Formula\n",
    "\n",
    "The minimum detectable effect at power (1-β) and significance α is:\n",
    "\n",
    "$$\\text{MDE} = (z_{1-\\alpha/2} + z_{1-\\beta}) \\cdot \\sqrt{2 \\cdot \\text{Var}(\\hat{\\theta})}$$\n",
    "\n",
    "For 80% power and α=0.05: MDE ≈ 2.8 × SE\n",
    "\n",
    "</details>\n",
    "\n",
    "**Documentation:**\n",
    "- [CJE GitHub](https://github.com/cimo-labs/cje)\n",
    "- [CJE Paper (arXiv)](https://arxiv.org/abs/2512.11150) — See Appendix F for full derivation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
