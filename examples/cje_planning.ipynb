{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CJE Planning: Optimize Your Evaluation Budget\n",
    "\n",
    "Before running a large evaluation, answer these questions:\n",
    "\n",
    "- **How many samples** do I need?\n",
    "- **How many oracle labels** are worth the cost?\n",
    "- **What effect size** can I reliably detect?\n",
    "\n",
    "CJE's planning tools help you find the optimal allocation between cheap surrogate scores and expensive oracle labels.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cimo-labs/cje/blob/main/examples/cje_planning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CJE\n",
    "!pip install -q --upgrade cje-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Planning Problem\n",
    "\n",
    "CJE calibrates cheap judge scores to match expensive oracle outcomes. The variance of your estimates depends on two components:\n",
    "\n",
    "$$\\text{Var}(\\hat{\\theta}) = \\frac{\\sigma^2_{\\text{eval}}}{n} + \\frac{\\sigma^2_{\\text{cal}}}{m}$$\n",
    "\n",
    "Where:\n",
    "- **n** = total samples (evaluated by cheap judge)\n",
    "- **m** = oracle-labeled samples (subset of n)\n",
    "- **ÏƒÂ²_eval** = evaluation variance (inherent noise in policy performance)\n",
    "- **ÏƒÂ²_cal** = calibration variance (uncertainty in learning judgeâ†’oracle mapping)\n",
    "\n",
    "**The tradeoff:** More oracle labels (â†‘m) reduces calibration uncertainty but costs more. CJE finds the optimal balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pilot Data\n",
    "\n",
    "Planning requires **pilot data** â€” a small sample to estimate the variance components. You can use:\n",
    "\n",
    "1. **Your own pilot study** (recommended): 100-500 samples with oracle labels\n",
    "2. **Arena sample data** (below): Real-world reference from Chatbot Arena\n",
    "\n",
    "The pilot data should be representative of your actual evaluation setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Arena sample data as reference\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"arena_sample\")\n",
    "if not (DATA_DIR / \"fresh_draws\" / \"base_responses.jsonl\").exists():\n",
    "    print(\"Downloading sample data...\")\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "    (DATA_DIR / \"fresh_draws\").mkdir(exist_ok=True)\n",
    "    \n",
    "    BASE_URL = \"https://raw.githubusercontent.com/cimo-labs/cje/main/examples/arena_sample\"\n",
    "    for f in [\"base_responses.jsonl\", \"clone_responses.jsonl\", \n",
    "              \"parallel_universe_prompt_responses.jsonl\", \"unhelpful_responses.jsonl\"]:\n",
    "        urllib.request.urlretrieve(f\"{BASE_URL}/fresh_draws/{f}\", DATA_DIR / \"fresh_draws\" / f)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(f\"Data exists at {DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Fit Variance Model\n\nThe variance model learns ÏƒÂ²_eval and ÏƒÂ²_cal from your pilot data by measuring estimate variance at different (n, m) allocations.\n\n**Important:** Use a **single policy** for fitting. The model assumes a consistent variance structure â€” mixing policies with different characteristics (e.g., base vs adversarial) violates this assumption and causes poor fit."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from cje import fit_variance_model\nfrom cje.data.fresh_draws import load_fresh_draws_auto\n\n# Load pilot data - use a SINGLE policy for variance model fitting\n# The 1/n + 1/m model assumes consistent variance structure\nbase_data = load_fresh_draws_auto(\"arena_sample/fresh_draws\", \"base\")\n\nprint(f\"Loaded base policy: {len(base_data.samples)} samples\")\nprint(f\"Oracle labels: {sum(1 for s in base_data.samples if s.oracle_label is not None)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fit the variance model using single policy (takes ~30 seconds)\n# Using multiple policies violates the model assumptions and causes poor fit\nmodel = fit_variance_model({\"base\": base_data}, verbose=True)\n\n# RÂ² > 0.85 indicates the 1/n + 1/m model fits well\nif model.r_squared < 0.5:\n    print(\"\\nâš ï¸  Low RÂ² suggests the variance model may not fit your data well.\")\n    print(\"   Check that oracle labels are randomly sampled within your pilot.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify Your Costs\n",
    "\n",
    "**Critical:** Use actual dollar costs per API call. This ensures budget is in real dollars.\n",
    "\n",
    "| Surrogate (Judge) | Oracle | Cost Ratio |\n",
    "|-------------------|--------|------------|\n",
    "| GPT-4o-mini ($0.01) | GPT-4o ($0.16) | 16Ã— |\n",
    "| Claude Haiku ($0.008) | Claude Sonnet ($0.09) | 11Ã— |\n",
    "| Llama-70B ($0.002) | Human ($2.00) | 1000Ã— |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import CostModel\n",
    "\n",
    "# Example: GPT-4o-mini as judge, GPT-4o as oracle\n",
    "cost_model = CostModel(\n",
    "    surrogate_cost=0.01,  # $/call for judge\n",
    "    oracle_cost=0.16      # $/call for oracle\n",
    ")\n",
    "\n",
    "print(f\"Surrogate cost: ${cost_model.surrogate_cost}/call\")\n",
    "print(f\"Oracle cost: ${cost_model.oracle_cost}/call\")\n",
    "print(f\"Cost ratio: {cost_model.oracle_cost/cost_model.surrogate_cost:.0f}Ã—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Budget-Constrained Planning\n",
    "\n",
    "**Question:** \"I have $X budget â€” what effect size can I reliably detect?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import plan_evaluation\n",
    "\n",
    "# Plan with $5,000 budget\n",
    "plan = plan_evaluation(\n",
    "    budget=5000,\n",
    "    variance_model=model,\n",
    "    cost_model=cost_model\n",
    ")\n",
    "\n",
    "print(plan.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the results\n",
    "print(f\"ðŸ“Š What this means:\")\n",
    "print(f\"\")\n",
    "print(f\"   1. Collect {plan.n_samples:,} responses, each scored by your surrogate judge\")\n",
    "print(f\"   2. Randomly label {plan.m_oracle} of them with oracle ({plan.oracle_fraction:.1%} of samples)\")\n",
    "print(f\"   3. Run CJE to get calibrated estimates\")\n",
    "print(f\"\")\n",
    "print(f\"   With this setup, you can detect a {plan.mde:.1%} difference between policies\")\n",
    "print(f\"   with 80% statistical power (Î±=0.05).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MDE-Constrained Planning\n",
    "\n",
    "**Question:** \"I need to detect X% differences â€” what will it cost?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje import plan_for_mde\n",
    "\n",
    "# Plan to detect 2% differences\n",
    "plan_2pct = plan_for_mde(\n",
    "    target_mde=0.02,\n",
    "    variance_model=model,\n",
    "    cost_model=cost_model\n",
    ")\n",
    "\n",
    "print(f\"To detect 2% differences with 80% power:\")\n",
    "print(f\"  Budget needed: ${plan_2pct.total_cost:,.0f}\")\n",
    "print(f\"  Samples: {plan_2pct.n_samples:,} total, {plan_2pct.m_oracle} oracle labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different MDE targets\n",
    "print(f\"ðŸ“Š MDE vs Budget Tradeoff\")\n",
    "print(f\"=\"*40)\n",
    "print(f\"{'MDE':<10} {'Budget':<15} {'Samples':<10} {'Oracle'}\")\n",
    "print(f\"-\"*40)\n",
    "\n",
    "for target in [0.05, 0.03, 0.02, 0.015, 0.01]:\n",
    "    p = plan_for_mde(target_mde=target, variance_model=model, cost_model=cost_model)\n",
    "    print(f\"{target:.1%}       ${p.total_cost:>10,.0f}    {p.n_samples:>7,}   {p.m_oracle:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Tradeoffs\n",
    "\n",
    "The planning dashboard shows three views:\n",
    "\n",
    "1. **MDE vs Budget** â€” How precision improves with spending\n",
    "2. **Power Curve** â€” Probability of detecting different effect sizes\n",
    "3. **Cost Sensitivity** â€” How oracle cost affects the tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cje.visualization import plot_planning_dashboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plot_planning_dashboard(model, cost_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The Planning Loop\n",
    "\n",
    "Planning is iterative. Start with one constraint and check if the other is acceptable:\n",
    "\n",
    "```python\n",
    "# \"I have $10K but need 1.5% MDE\"\n",
    "plan = plan_evaluation(budget=10000, ...)  # â†’ MDE = 2.1% (too high!)\n",
    "plan = plan_for_mde(target_mde=0.015, ...) # â†’ $18K (too expensive!)\n",
    "plan = plan_for_mde(target_mde=0.018, ...) # â†’ $12K (compromise?)\n",
    "```\n",
    "\n",
    "**Rule of thumb:** Target MDE should be 2-3Ã— smaller than differences you actually care about. If you care about 5% differences, aim for 2% MDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive planning example\n",
    "print(\"Example planning session:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Start with budget constraint\n",
    "initial = plan_evaluation(budget=10000, variance_model=model, cost_model=cost_model)\n",
    "print(f\"\\n1. With $10K budget: MDE = {initial.mde:.1%}\")\n",
    "\n",
    "# Check what it costs to hit a tighter MDE\n",
    "target = plan_for_mde(target_mde=0.015, variance_model=model, cost_model=cost_model)\n",
    "print(f\"2. To hit 1.5% MDE: need ${target.total_cost:,.0f}\")\n",
    "\n",
    "# Find a compromise\n",
    "compromise = plan_for_mde(target_mde=0.02, variance_model=model, cost_model=cost_model)\n",
    "print(f\"3. Compromise at 2% MDE: ${compromise.total_cost:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### Quick Reference\n\n```python\nfrom cje import fit_variance_model, CostModel, plan_evaluation, plan_for_mde\nfrom cje.data.fresh_draws import load_fresh_draws_auto\n\n# 1. Fit variance model from pilot data (use SINGLE policy)\nbase_data = load_fresh_draws_auto(\"pilot_dir\", \"base\")\nmodel = fit_variance_model({\"base\": base_data})\n\n# 2. Specify costs (use actual $/call)\ncost_model = CostModel(surrogate_cost=0.01, oracle_cost=0.16)\n\n# 3a. Budget â†’ MDE\nplan = plan_evaluation(budget=5000, variance_model=model, cost_model=cost_model)\n\n# 3b. MDE â†’ Budget  \nplan = plan_for_mde(target_mde=0.02, variance_model=model, cost_model=cost_model)\n```\n\n### Next Steps\n\nOnce you have your plan, run the evaluation:\n\n[![Core Tutorial](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cimo-labs/cje/blob/main/examples/cje_core_demo.ipynb)\n\n**Documentation:**\n- [CJE GitHub](https://github.com/cimo-labs/cje)\n- [Blog: Why Your Metrics Lie](https://cimolabs.com/blog/metrics-lying)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}